{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('D:\\\\ai\\\\기말대체\\\\Data set_1.csv')\n",
    "test_data=pd.read_csv('D:\\\\ai\\\\기말대체\\\\Data set_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=['로','에','등','으로','및','과','되며','한']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt=Okt()\n",
    "X_train=[]\n",
    "for sentence in train_data['title']:\n",
    "    temp_X=[]\n",
    "    temp_X=okt.morphs(sentence,stem=True)\n",
    "    temp_X=[word for word in temp_X if not word in stopwords]\n",
    "    X_train.append(temp_X)\n",
    "X_test=[]\n",
    "for sentence in test_data['title']:\n",
    "    temp_X=[]\n",
    "    temp_X=okt.morphs(sentence,stem=True)\n",
    "    temp_X=[word for word in temp_X if not word in stopwords]\n",
    "    X_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CMG', '제약', '외국인', '12만', '9000', '주', '순', '매수', '주가', '058'], ['CMG', '제약', '외국인', '8만', '6000', '주', '순', '매수', '주가', '246'], ['CMG', '제약', '검색', '상위', '랭킹', '주가', '159']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fnRASSI', '씨', '케이', '에이치', '900120', '1185', '상승'], ['fnRASSI', '씨', '케이', '에이치', '900120', '899', '상승'], ['코스닥', '人', '씨', '케이', '에이치', '화장품', '·', '건기', '식', '사업', '두', '마리', '토끼', '잡다']]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화한 단어를 정수인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_words=35000\n",
    "tokenizer=Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train=tokenizer.texts_to_sequences(X_train)\n",
    "X_test=tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105, 70, 22, 858, 583, 8, 18, 20, 4, 859], [105, 70, 22, 860, 584, 8, 18, 20, 4, 585], [105, 70, 44, 50, 51, 4, 445]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12, 66, 180, 202, 1897, 1], [12, 66, 180, 202, 1897, 1], [35, 66, 180, 202, 763, 5, 662, 65, 1292]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label data -1,0,1에 대해서 one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[]\n",
    "y_test=[]\n",
    "\n",
    "for i in range(len(train_data['label'])):\n",
    "    if train_data['label'].iloc[i]==1:\n",
    "        y_train.append([0,0,1])\n",
    "    elif train_data['label'].iloc[i]==0:\n",
    "        y_train.append([0,1,0])\n",
    "    elif train_data['label'].iloc[i]==-1:\n",
    "        y_train.append([1,0,0])\n",
    "\n",
    "for i in range(len(test_data['label'])):\n",
    "    if test_data['label'].iloc[i]==1:\n",
    "        y_test.append([0,0,1])\n",
    "    elif test_data['label'].iloc[i]==0:\n",
    "        y_test.append([0,1,0])\n",
    "    elif test_data['label'].iloc[i]==-1:\n",
    "        y_test.append([1,0,0])\n",
    "        \n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 earlystopping callback적용한 모델2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "max_len=20\n",
    "X_train=pad_sequences(X_train, maxlen=max_len)\n",
    "X_test=pad_sequences(X_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_words,100))\n",
    "model2.add(LSTM(128)) #layer에 포함되는 unit개수가 128개일때 대체로 괜찮은가보다\n",
    "model2.add(Dense(3, activation='softmax'))  # 활성화 함수 softmax 사용\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "import os\n",
    "MODEL_DIR = './model_save/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "   os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일명에 epoch와 val_loss를 기록하도록 설정 \n",
    "modelpath=\"./model_save/{epoch:02d}-{val_loss:.4f}.hdf5\" \n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\.conda\\envs\\ai\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 946 samples, validate on 949 samples\n",
      "Epoch 1/3000\n",
      " - 2s - loss: 0.8810 - accuracy: 0.6353 - val_loss: 0.5927 - val_accuracy: 0.7345\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59275, saving model to ./model_save/01-0.5927.hdf5\n",
      "Epoch 2/3000\n",
      " - 2s - loss: 0.4658 - accuracy: 0.8214 - val_loss: 0.3825 - val_accuracy: 0.8377\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59275 to 0.38248, saving model to ./model_save/02-0.3825.hdf5\n",
      "Epoch 3/3000\n",
      " - 2s - loss: 0.2269 - accuracy: 0.9207 - val_loss: 0.3024 - val_accuracy: 0.8830\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38248 to 0.30239, saving model to ./model_save/03-0.3024.hdf5\n",
      "Epoch 4/3000\n",
      " - 2s - loss: 0.0975 - accuracy: 0.9641 - val_loss: 0.3436 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30239\n",
      "Epoch 5/3000\n",
      " - 2s - loss: 0.0398 - accuracy: 0.9958 - val_loss: 0.7290 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30239\n",
      "Epoch 6/3000\n",
      " - 2s - loss: 0.0519 - accuracy: 0.9926 - val_loss: 0.3139 - val_accuracy: 0.9009\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30239\n",
      "Epoch 7/3000\n",
      " - 2s - loss: 0.0175 - accuracy: 0.9968 - val_loss: 0.2856 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.30239 to 0.28560, saving model to ./model_save/07-0.2856.hdf5\n",
      "Epoch 8/3000\n",
      " - 2s - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.4064 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28560\n",
      "Epoch 9/3000\n",
      " - 2s - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.3687 - val_accuracy: 0.8957\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28560\n",
      "Epoch 10/3000\n",
      " - 2s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4170 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28560\n",
      "Epoch 11/3000\n",
      " - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28560\n",
      "Epoch 12/3000\n",
      " - 2s - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.3108 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28560\n",
      "Epoch 13/3000\n",
      " - 2s - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.2763 - val_accuracy: 0.9041\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28560 to 0.27629, saving model to ./model_save/13-0.2763.hdf5\n",
      "Epoch 14/3000\n",
      " - 2s - loss: 0.0161 - accuracy: 0.9979 - val_loss: 0.2634 - val_accuracy: 0.9125\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27629 to 0.26339, saving model to ./model_save/14-0.2634.hdf5\n",
      "Epoch 15/3000\n",
      " - 2s - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.3233 - val_accuracy: 0.9094\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26339\n",
      "Epoch 16/3000\n",
      " - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9083\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26339\n",
      "Epoch 17/3000\n",
      " - 2s - loss: 9.2347e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26339\n",
      "Epoch 18/3000\n",
      " - 2s - loss: 6.2063e-04 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26339\n",
      "Epoch 19/3000\n",
      " - 2s - loss: 4.6063e-04 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9031\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.26339\n",
      "Epoch 20/3000\n",
      " - 2s - loss: 3.5916e-04 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.9031\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.26339\n",
      "Epoch 21/3000\n",
      " - 2s - loss: 2.9157e-04 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9031\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.26339\n",
      "Epoch 22/3000\n",
      " - 2s - loss: 2.4613e-04 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9020\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.26339\n",
      "Epoch 23/3000\n",
      " - 2s - loss: 2.0555e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9009\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.26339\n",
      "Epoch 24/3000\n",
      " - 2s - loss: 1.8049e-04 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.8999\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.26339\n",
      "Epoch 25/3000\n",
      " - 2s - loss: 1.5654e-04 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.9009\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.26339\n",
      "Epoch 26/3000\n",
      " - 2s - loss: 1.4006e-04 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.8967\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.26339\n",
      "Epoch 27/3000\n",
      " - 2s - loss: 1.2454e-04 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.8978\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.26339\n",
      "Epoch 28/3000\n",
      " - 2s - loss: 1.1376e-04 - accuracy: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.8957\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.26339\n",
      "Epoch 29/3000\n",
      " - 2s - loss: 1.0260e-04 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.26339\n",
      "Epoch 30/3000\n",
      " - 2s - loss: 9.4928e-05 - accuracy: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.8946\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.26339\n",
      "Epoch 31/3000\n",
      " - 2s - loss: 8.5171e-05 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.26339\n",
      "Epoch 32/3000\n",
      " - 2s - loss: 7.8364e-05 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.26339\n",
      "Epoch 33/3000\n",
      " - 2s - loss: 7.3177e-05 - accuracy: 1.0000 - val_loss: 0.5318 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.26339\n",
      "Epoch 34/3000\n",
      " - 2s - loss: 6.7958e-05 - accuracy: 1.0000 - val_loss: 0.5371 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.26339\n",
      "Epoch 35/3000\n",
      " - 2s - loss: 6.3511e-05 - accuracy: 1.0000 - val_loss: 0.5441 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.26339\n",
      "Epoch 36/3000\n",
      " - 2s - loss: 5.8434e-05 - accuracy: 1.0000 - val_loss: 0.5489 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.26339\n",
      "Epoch 37/3000\n",
      " - 2s - loss: 5.6522e-05 - accuracy: 1.0000 - val_loss: 0.5573 - val_accuracy: 0.8915\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.26339\n",
      "Epoch 38/3000\n",
      " - 2s - loss: 5.0771e-05 - accuracy: 1.0000 - val_loss: 0.5596 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.26339\n",
      "Epoch 39/3000\n",
      " - 2s - loss: 4.8903e-05 - accuracy: 1.0000 - val_loss: 0.5654 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.26339\n",
      "Epoch 40/3000\n",
      " - 2s - loss: 4.6476e-05 - accuracy: 1.0000 - val_loss: 0.5699 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.26339\n",
      "Epoch 41/3000\n",
      " - 2s - loss: 4.4773e-05 - accuracy: 1.0000 - val_loss: 0.5776 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.26339\n",
      "Epoch 42/3000\n",
      " - 2s - loss: 4.2262e-05 - accuracy: 1.0000 - val_loss: 0.5803 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.26339\n",
      "Epoch 43/3000\n",
      " - 2s - loss: 4.0213e-05 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.26339\n",
      "Epoch 44/3000\n",
      " - 2s - loss: 3.6317e-05 - accuracy: 1.0000 - val_loss: 0.5901 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.26339\n",
      "Epoch 45/3000\n",
      " - 2s - loss: 3.5172e-05 - accuracy: 1.0000 - val_loss: 0.5945 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.26339\n",
      "Epoch 46/3000\n",
      " - 2s - loss: 3.3022e-05 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.26339\n",
      "Epoch 47/3000\n",
      " - 2s - loss: 3.0990e-05 - accuracy: 1.0000 - val_loss: 0.6032 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.26339\n",
      "Epoch 48/3000\n",
      " - 2s - loss: 2.9773e-05 - accuracy: 1.0000 - val_loss: 0.6078 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.26339\n",
      "Epoch 49/3000\n",
      " - 2s - loss: 2.8867e-05 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.26339\n",
      "Epoch 50/3000\n",
      " - 2s - loss: 2.7754e-05 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.26339\n",
      "Epoch 51/3000\n",
      " - 2s - loss: 2.6405e-05 - accuracy: 1.0000 - val_loss: 0.6199 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.26339\n",
      "Epoch 52/3000\n",
      " - 2s - loss: 2.5201e-05 - accuracy: 1.0000 - val_loss: 0.6246 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.26339\n",
      "Epoch 53/3000\n",
      " - 2s - loss: 2.4060e-05 - accuracy: 1.0000 - val_loss: 0.6284 - val_accuracy: 0.8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00053: val_loss did not improve from 0.26339\n",
      "Epoch 54/3000\n",
      " - 2s - loss: 2.3283e-05 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.26339\n",
      "Epoch 55/3000\n",
      " - 2s - loss: 2.2510e-05 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.26339\n",
      "Epoch 56/3000\n",
      " - 2s - loss: 2.1388e-05 - accuracy: 1.0000 - val_loss: 0.6381 - val_accuracy: 0.8915\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.26339\n",
      "Epoch 57/3000\n",
      " - 2s - loss: 2.0859e-05 - accuracy: 1.0000 - val_loss: 0.6432 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.26339\n",
      "Epoch 58/3000\n",
      " - 2s - loss: 2.1238e-05 - accuracy: 1.0000 - val_loss: 0.6438 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.26339\n",
      "Epoch 59/3000\n",
      " - 2s - loss: 1.9579e-05 - accuracy: 1.0000 - val_loss: 0.6481 - val_accuracy: 0.8915\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.26339\n",
      "Epoch 60/3000\n",
      " - 2s - loss: 1.8155e-05 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.26339\n",
      "Epoch 61/3000\n",
      " - 2s - loss: 1.7785e-05 - accuracy: 1.0000 - val_loss: 0.6539 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.26339\n",
      "Epoch 62/3000\n",
      " - 2s - loss: 1.7723e-05 - accuracy: 1.0000 - val_loss: 0.6564 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.26339\n",
      "Epoch 63/3000\n",
      " - 2s - loss: 1.6993e-05 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.26339\n",
      "Epoch 64/3000\n",
      " - 2s - loss: 1.6455e-05 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.26339\n",
      "Epoch 65/3000\n",
      " - 2s - loss: 1.5072e-05 - accuracy: 1.0000 - val_loss: 0.6649 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.26339\n",
      "Epoch 66/3000\n",
      " - 2s - loss: 1.5283e-05 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.26339\n",
      "Epoch 67/3000\n",
      " - 2s - loss: 1.4624e-05 - accuracy: 1.0000 - val_loss: 0.6714 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.26339\n",
      "Epoch 68/3000\n",
      " - 2s - loss: 1.4322e-05 - accuracy: 1.0000 - val_loss: 0.6750 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.26339\n",
      "Epoch 69/3000\n",
      " - 2s - loss: 1.3725e-05 - accuracy: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.26339\n",
      "Epoch 70/3000\n",
      " - 2s - loss: 1.3573e-05 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.26339\n",
      "Epoch 71/3000\n",
      " - 2s - loss: 1.2602e-05 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.26339\n",
      "Epoch 72/3000\n",
      " - 2s - loss: 1.2468e-05 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.26339\n",
      "Epoch 73/3000\n",
      " - 2s - loss: 1.1874e-05 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.26339\n",
      "Epoch 74/3000\n",
      " - 2s - loss: 1.1630e-05 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26339\n",
      "Epoch 75/3000\n",
      " - 2s - loss: 1.1413e-05 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.26339\n",
      "Epoch 76/3000\n",
      " - 2s - loss: 1.1073e-05 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.8862\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.26339\n",
      "Epoch 77/3000\n",
      " - 2s - loss: 1.0740e-05 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8862\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.26339\n",
      "Epoch 78/3000\n",
      " - 2s - loss: 1.0843e-05 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8862\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.26339\n",
      "Epoch 79/3000\n",
      " - 2s - loss: 1.0099e-05 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.26339\n",
      "Epoch 80/3000\n",
      " - 2s - loss: 9.8353e-06 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.26339\n",
      "Epoch 81/3000\n",
      " - 2s - loss: 9.3908e-06 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.26339\n",
      "Epoch 82/3000\n",
      " - 2s - loss: 9.3816e-06 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.26339\n",
      "Epoch 83/3000\n",
      " - 2s - loss: 8.8341e-06 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.26339\n",
      "Epoch 84/3000\n",
      " - 2s - loss: 8.8028e-06 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.26339\n",
      "Epoch 85/3000\n",
      " - 2s - loss: 8.7294e-06 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.26339\n",
      "Epoch 86/3000\n",
      " - 2s - loss: 8.3606e-06 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.26339\n",
      "Epoch 87/3000\n",
      " - 2s - loss: 8.0455e-06 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.8830\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.26339\n",
      "Epoch 88/3000\n",
      " - 2s - loss: 7.8149e-06 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.8788\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.26339\n",
      "Epoch 89/3000\n",
      " - 2s - loss: 7.9990e-06 - accuracy: 1.0000 - val_loss: 0.7275 - val_accuracy: 0.8862\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.26339\n",
      "Epoch 90/3000\n",
      " - 2s - loss: 7.4055e-06 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.26339\n",
      "Epoch 91/3000\n",
      " - 2s - loss: 7.3819e-06 - accuracy: 1.0000 - val_loss: 0.7314 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.26339\n",
      "Epoch 92/3000\n",
      " - 2s - loss: 7.5041e-06 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.26339\n",
      "Epoch 93/3000\n",
      " - 2s - loss: 7.1881e-06 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.26339\n",
      "Epoch 94/3000\n",
      " - 2s - loss: 6.5879e-06 - accuracy: 1.0000 - val_loss: 0.7391 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.26339\n",
      "Epoch 95/3000\n",
      " - 2s - loss: 6.7596e-06 - accuracy: 1.0000 - val_loss: 0.7413 - val_accuracy: 0.8830\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.26339\n",
      "Epoch 96/3000\n",
      " - 2s - loss: 6.6848e-06 - accuracy: 1.0000 - val_loss: 0.7428 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.26339\n",
      "Epoch 97/3000\n",
      " - 2s - loss: 6.3015e-06 - accuracy: 1.0000 - val_loss: 0.7439 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.26339\n",
      "Epoch 98/3000\n",
      " - 2s - loss: 6.2865e-06 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.26339\n",
      "Epoch 99/3000\n",
      " - 2s - loss: 5.9530e-06 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.26339\n",
      "Epoch 100/3000\n",
      " - 2s - loss: 5.9636e-06 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.26339\n",
      "Epoch 101/3000\n",
      " - 2s - loss: 5.9585e-06 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.26339\n",
      "Epoch 102/3000\n",
      " - 2s - loss: 5.6197e-06 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.26339\n",
      "Epoch 103/3000\n",
      " - 2s - loss: 5.5279e-06 - accuracy: 1.0000 - val_loss: 0.7592 - val_accuracy: 0.8851\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.26339\n",
      "Epoch 104/3000\n",
      " - 2s - loss: 5.1807e-06 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.8788\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.26339\n",
      "Epoch 105/3000\n",
      " - 2s - loss: 5.3084e-06 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.8788\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.26339\n",
      "Epoch 106/3000\n",
      " - 2s - loss: 5.0896e-06 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.26339\n",
      "Epoch 107/3000\n",
      " - 2s - loss: 5.1557e-06 - accuracy: 1.0000 - val_loss: 0.7654 - val_accuracy: 0.8809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00107: val_loss did not improve from 0.26339\n",
      "Epoch 108/3000\n",
      " - 2s - loss: 4.9389e-06 - accuracy: 1.0000 - val_loss: 0.7667 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.26339\n",
      "Epoch 109/3000\n",
      " - 2s - loss: 4.6722e-06 - accuracy: 1.0000 - val_loss: 0.7717 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.26339\n",
      "Epoch 110/3000\n",
      " - 2s - loss: 4.7812e-06 - accuracy: 1.0000 - val_loss: 0.7718 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.26339\n",
      "Epoch 111/3000\n",
      " - 2s - loss: 4.6020e-06 - accuracy: 1.0000 - val_loss: 0.7731 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.26339\n",
      "Epoch 112/3000\n",
      " - 2s - loss: 4.4846e-06 - accuracy: 1.0000 - val_loss: 0.7760 - val_accuracy: 0.8830\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.26339\n",
      "Epoch 113/3000\n",
      " - 2s - loss: 4.2769e-06 - accuracy: 1.0000 - val_loss: 0.7772 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.26339\n",
      "Epoch 114/3000\n",
      " - 2s - loss: 4.6433e-06 - accuracy: 1.0000 - val_loss: 0.7796 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.26339\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3000, verbose=2, callbacks=[checkpointer,early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.font_manager as fm\n",
    "#fm.get_fontconfig_fonts()\n",
    "#font_path=\"D:\\\\ai\\\\기말대체\\\\NanumFontSetup_TTF_GOTHIC\\\\NanumGothic.ttf\"\n",
    "#font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "#plt.rc('font', family=font_name, size=12) \n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title('Comparison of error rate and accuracy between training and testing datasets(model2)', fontsize=14)\n",
    "\n",
    "plt.plot(hist2.history['loss'])      # 학습 데이터셋의 loss   -> loss \n",
    "plt.plot(hist2.history['val_loss'])  # 테스트 데이터셋의 loss -> val_loss\n",
    "\n",
    "plt.plot(hist2.history['accuracy'])      # 학습 데이터셋의 accuracy    -> accuracy \n",
    "plt.plot(hist2.history['val_accuracy'])  # 테스트 데이터셋의 accuracy  -> val_accuracy \n",
    "\n",
    "plt.legend(['loss','val_loss','accuracy', 'val_accuracy' ])     # 범례\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('model2.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
