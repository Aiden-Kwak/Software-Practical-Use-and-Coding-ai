{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('D:\\\\ai\\\\기말대체\\\\Data set_1.csv')\n",
    "test_data=pd.read_csv('D:\\\\ai\\\\기말대체\\\\Data set_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=['로','에','등','으로','및','과','되며','한']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt=Okt()\n",
    "X_train=[]\n",
    "for sentence in train_data['title']:\n",
    "    temp_X=[]\n",
    "    temp_X=okt.morphs(sentence,stem=True)\n",
    "    temp_X=[word for word in temp_X if not word in stopwords]\n",
    "    X_train.append(temp_X)\n",
    "X_test=[]\n",
    "for sentence in test_data['title']:\n",
    "    temp_X=[]\n",
    "    temp_X=okt.morphs(sentence,stem=True)\n",
    "    temp_X=[word for word in temp_X if not word in stopwords]\n",
    "    X_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CMG', '제약', '외국인', '12만', '9000', '주', '순', '매수', '주가', '058'], ['CMG', '제약', '외국인', '8만', '6000', '주', '순', '매수', '주가', '246'], ['CMG', '제약', '검색', '상위', '랭킹', '주가', '159']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fnRASSI', '씨', '케이', '에이치', '900120', '1185', '상승'], ['fnRASSI', '씨', '케이', '에이치', '900120', '899', '상승'], ['코스닥', '人', '씨', '케이', '에이치', '화장품', '·', '건기', '식', '사업', '두', '마리', '토끼', '잡다']]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화한 단어를 정수인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_words=35000\n",
    "tokenizer=Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train=tokenizer.texts_to_sequences(X_train)\n",
    "X_test=tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105, 70, 22, 858, 583, 8, 18, 20, 4, 859], [105, 70, 22, 860, 584, 8, 18, 20, 4, 585], [105, 70, 44, 50, 51, 4, 445]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12, 66, 180, 202, 1897, 1], [12, 66, 180, 202, 1897, 1], [35, 66, 180, 202, 763, 5, 662, 65, 1292]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label data -1,0,1에 대해서 one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[]\n",
    "y_test=[]\n",
    "\n",
    "for i in range(len(train_data['label'])):\n",
    "    if train_data['label'].iloc[i]==1:\n",
    "        y_train.append([0,0,1])\n",
    "    elif train_data['label'].iloc[i]==0:\n",
    "        y_train.append([0,1,0])\n",
    "    elif train_data['label'].iloc[i]==-1:\n",
    "        y_train.append([1,0,0])\n",
    "\n",
    "for i in range(len(test_data['label'])):\n",
    "    if test_data['label'].iloc[i]==1:\n",
    "        y_test.append([0,0,1])\n",
    "    elif test_data['label'].iloc[i]==0:\n",
    "        y_test.append([0,1,0])\n",
    "    elif test_data['label'].iloc[i]==-1:\n",
    "        y_test.append([1,0,0])\n",
    "        \n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 earlystopping callback적용한 모델2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "max_len=20\n",
    "X_train=pad_sequences(X_train, maxlen=max_len)\n",
    "X_test=pad_sequences(X_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(max_words,100))\n",
    "model3.add(LSTM(128)) #layer에 포함되는 unit개수가 128개일때 대체로 괜찮은가보다\n",
    "model3.add(Dense(3, activation='softmax'))  # 활성화 함수 softmax 사용\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "import os\n",
    "MODEL_DIR = './model3_save/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "   os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일명에 epoch와 val_loss를 기록하도록 설정 \n",
    "modelpath=\"./model3_save/{epoch:02d}-{val_loss:.4f}.hdf5\" \n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\.conda\\envs\\ai\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 851 samples, validate on 95 samples\n",
      "Epoch 1/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 0.6991 - accuracy: 0.7192 - val_loss: 0.6602 - val_accuracy: 0.7684\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66025, saving model to ./model3_save/01-0.6602.hdf5\n",
      "Epoch 2/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 0.2486 - accuracy: 0.9083 - val_loss: 0.5428 - val_accuracy: 0.7789\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66025 to 0.54284, saving model to ./model3_save/02-0.5428.hdf5\n",
      "Epoch 3/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 0.0881 - accuracy: 0.9788 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.54284\n",
      "Epoch 4/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 0.0382 - accuracy: 0.9953 - val_loss: 0.5703 - val_accuracy: 0.8105\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.54284\n",
      "Epoch 5/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.6277 - val_accuracy: 0.7158\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.54284\n",
      "Epoch 6/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.5930 - val_accuracy: 0.7895\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.54284\n",
      "Epoch 7/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6642 - val_accuracy: 0.7895\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.54284\n",
      "Epoch 8/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 8.3153e-04 - accuracy: 1.0000 - val_loss: 0.6707 - val_accuracy: 0.7579\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.54284\n",
      "Epoch 9/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 5.2253e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.7579\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.54284\n",
      "Epoch 10/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 3.9437e-04 - accuracy: 1.0000 - val_loss: 0.7236 - val_accuracy: 0.7053\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.54284\n",
      "Epoch 11/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 3.0667e-04 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.7053\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.54284\n",
      "Epoch 12/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 2.5902e-04 - accuracy: 1.0000 - val_loss: 0.7863 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.54284\n",
      "Epoch 13/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 2.0284e-04 - accuracy: 1.0000 - val_loss: 0.8216 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.54284\n",
      "Epoch 14/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.6147e-04 - accuracy: 1.0000 - val_loss: 0.8336 - val_accuracy: 0.7053\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.54284\n",
      "Epoch 15/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.4459e-04 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.54284\n",
      "Epoch 16/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.1984e-04 - accuracy: 1.0000 - val_loss: 0.8681 - val_accuracy: 0.7053\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.54284\n",
      "Epoch 17/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 9.8797e-05 - accuracy: 1.0000 - val_loss: 0.8931 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.54284\n",
      "Epoch 18/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 8.6928e-05 - accuracy: 1.0000 - val_loss: 0.9095 - val_accuracy: 0.7053\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.54284\n",
      "Epoch 19/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 8.1091e-05 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.54284\n",
      "Epoch 20/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 6.9207e-05 - accuracy: 1.0000 - val_loss: 0.9608 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.54284\n",
      "Epoch 21/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 6.1810e-05 - accuracy: 1.0000 - val_loss: 0.9903 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.54284\n",
      "Epoch 22/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 5.1629e-05 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.54284\n",
      "Epoch 23/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 4.7504e-05 - accuracy: 1.0000 - val_loss: 1.0049 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.54284\n",
      "Epoch 24/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 4.3540e-05 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.54284\n",
      "Epoch 25/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 4.1078e-05 - accuracy: 1.0000 - val_loss: 1.0719 - val_accuracy: 0.7053\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.54284\n",
      "Epoch 26/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 3.3317e-05 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.54284\n",
      "Epoch 27/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 3.4043e-05 - accuracy: 1.0000 - val_loss: 1.0658 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.54284\n",
      "Epoch 28/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 2.9400e-05 - accuracy: 1.0000 - val_loss: 1.0782 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.54284\n",
      "Epoch 29/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 2.8551e-05 - accuracy: 1.0000 - val_loss: 1.1307 - val_accuracy: 0.6947\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.54284\n",
      "Epoch 30/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 2.5010e-05 - accuracy: 1.0000 - val_loss: 1.1284 - val_accuracy: 0.7053\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.54284\n",
      "Epoch 31/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 2.3206e-05 - accuracy: 1.0000 - val_loss: 1.1751 - val_accuracy: 0.6842\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.54284\n",
      "Epoch 32/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 2.1366e-05 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.6842\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.54284\n",
      "Epoch 33/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.9240e-05 - accuracy: 1.0000 - val_loss: 1.1665 - val_accuracy: 0.7053\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.54284\n",
      "Epoch 34/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.8120e-05 - accuracy: 1.0000 - val_loss: 1.2064 - val_accuracy: 0.6842\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.54284\n",
      "Epoch 35/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.7082e-05 - accuracy: 1.0000 - val_loss: 1.2372 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.54284\n",
      "Epoch 36/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.5971e-05 - accuracy: 1.0000 - val_loss: 1.2485 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.54284\n",
      "Epoch 37/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.3249e-05 - accuracy: 1.0000 - val_loss: 1.2052 - val_accuracy: 0.7053\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.54284\n",
      "Epoch 38/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.4072e-05 - accuracy: 1.0000 - val_loss: 1.2559 - val_accuracy: 0.6737\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.54284\n",
      "Epoch 39/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.2891e-05 - accuracy: 1.0000 - val_loss: 1.2860 - val_accuracy: 0.6737\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.54284\n",
      "Epoch 40/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.1127e-05 - accuracy: 1.0000 - val_loss: 1.2411 - val_accuracy: 0.6842\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.54284\n",
      "Epoch 41/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851/851 [==============================] - 3s 4ms/step - loss: 1.1372e-05 - accuracy: 1.0000 - val_loss: 1.2970 - val_accuracy: 0.6737\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.54284\n",
      "Epoch 42/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.0387e-05 - accuracy: 1.0000 - val_loss: 1.2589 - val_accuracy: 0.6842\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.54284\n",
      "Epoch 43/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 1.0201e-05 - accuracy: 1.0000 - val_loss: 1.3294 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.54284\n",
      "Epoch 44/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 9.0789e-06 - accuracy: 1.0000 - val_loss: 1.3566 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.54284\n",
      "Epoch 45/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 7.7419e-06 - accuracy: 1.0000 - val_loss: 1.3044 - val_accuracy: 0.6842\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.54284\n",
      "Epoch 46/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 8.3980e-06 - accuracy: 1.0000 - val_loss: 1.3606 - val_accuracy: 0.6737\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.54284\n",
      "Epoch 47/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 7.7943e-06 - accuracy: 1.0000 - val_loss: 1.4011 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.54284\n",
      "Epoch 48/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 7.1849e-06 - accuracy: 1.0000 - val_loss: 1.3823 - val_accuracy: 0.6737\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.54284\n",
      "Epoch 49/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 6.9374e-06 - accuracy: 1.0000 - val_loss: 1.4568 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.54284\n",
      "Epoch 50/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 5.7993e-06 - accuracy: 1.0000 - val_loss: 1.3837 - val_accuracy: 0.6842\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.54284\n",
      "Epoch 51/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 6.0059e-06 - accuracy: 1.0000 - val_loss: 1.4813 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.54284\n",
      "Epoch 52/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 5.8121e-06 - accuracy: 1.0000 - val_loss: 1.4104 - val_accuracy: 0.6737\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.54284\n",
      "Epoch 53/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 4.9929e-06 - accuracy: 1.0000 - val_loss: 1.4239 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.54284\n",
      "Epoch 54/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 5.3920e-06 - accuracy: 1.0000 - val_loss: 1.5084 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.54284\n",
      "Epoch 55/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 4.3015e-06 - accuracy: 1.0000 - val_loss: 1.4457 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.54284\n",
      "Epoch 56/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 4.6156e-06 - accuracy: 1.0000 - val_loss: 1.5098 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.54284\n",
      "Epoch 57/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 4.2967e-06 - accuracy: 1.0000 - val_loss: 1.5030 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.54284\n",
      "Epoch 58/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 3.7124e-06 - accuracy: 1.0000 - val_loss: 1.4745 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.54284\n",
      "Epoch 59/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 3.9990e-06 - accuracy: 1.0000 - val_loss: 1.4934 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.54284\n",
      "Epoch 60/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 3.8504e-06 - accuracy: 1.0000 - val_loss: 1.5380 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.54284\n",
      "Epoch 61/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 3.5086e-06 - accuracy: 1.0000 - val_loss: 1.5621 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.54284\n",
      "Epoch 62/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 3.2154e-06 - accuracy: 1.0000 - val_loss: 1.5677 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.54284\n",
      "Epoch 63/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 3.0822e-06 - accuracy: 1.0000 - val_loss: 1.6325 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.54284\n",
      "Epoch 64/3000\n",
      "851/851 [==============================] - 3s 4ms/step - loss: 2.8044e-06 - accuracy: 1.0000 - val_loss: 1.5859 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.54284\n",
      "Epoch 65/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 2.8381e-06 - accuracy: 1.0000 - val_loss: 1.6533 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.54284\n",
      "Epoch 66/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 2.8252e-06 - accuracy: 1.0000 - val_loss: 1.6772 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.54284\n",
      "Epoch 67/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 2.5482e-06 - accuracy: 1.0000 - val_loss: 1.6885 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.54284\n",
      "Epoch 68/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 2.4065e-06 - accuracy: 1.0000 - val_loss: 1.7010 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.54284\n",
      "Epoch 69/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 2.2431e-06 - accuracy: 1.0000 - val_loss: 1.7175 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.54284\n",
      "Epoch 70/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 2.1613e-06 - accuracy: 1.0000 - val_loss: 1.6919 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.54284\n",
      "Epoch 71/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 2.0168e-06 - accuracy: 1.0000 - val_loss: 1.7198 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.54284\n",
      "Epoch 72/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 1.9028e-06 - accuracy: 1.0000 - val_loss: 1.6963 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.54284\n",
      "Epoch 73/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 1.6685e-06 - accuracy: 1.0000 - val_loss: 1.6741 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.54284\n",
      "Epoch 74/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 1.7328e-06 - accuracy: 1.0000 - val_loss: 1.6785 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.54284\n",
      "Epoch 75/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 1.7740e-06 - accuracy: 1.0000 - val_loss: 1.7056 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.54284\n",
      "Epoch 76/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 1.7041e-06 - accuracy: 1.0000 - val_loss: 1.7565 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.54284\n",
      "Epoch 77/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 1.3578e-06 - accuracy: 1.0000 - val_loss: 1.7151 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.54284\n",
      "Epoch 78/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 1.6788e-06 - accuracy: 1.0000 - val_loss: 1.8412 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.54284\n",
      "Epoch 79/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 1.3650e-06 - accuracy: 1.0000 - val_loss: 1.8304 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.54284\n",
      "Epoch 80/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 1.3169e-06 - accuracy: 1.0000 - val_loss: 1.8360 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.54284\n",
      "Epoch 81/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 1.2408e-06 - accuracy: 1.0000 - val_loss: 1.8544 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.54284\n",
      "Epoch 82/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851/851 [==============================] - 4s 4ms/step - loss: 1.1624e-06 - accuracy: 1.0000 - val_loss: 1.8341 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.54284\n",
      "Epoch 83/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 1.1509e-06 - accuracy: 1.0000 - val_loss: 1.8156 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.54284\n",
      "Epoch 84/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 1.1437e-06 - accuracy: 1.0000 - val_loss: 1.9511 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.54284\n",
      "Epoch 85/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 1.0240e-06 - accuracy: 1.0000 - val_loss: 1.8834 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.54284\n",
      "Epoch 86/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 9.7997e-07 - accuracy: 1.0000 - val_loss: 1.9593 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.54284\n",
      "Epoch 87/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 8.9538e-07 - accuracy: 1.0000 - val_loss: 1.8719 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.54284\n",
      "Epoch 88/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 9.0840e-07 - accuracy: 1.0000 - val_loss: 1.9299 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.54284\n",
      "Epoch 89/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 9.1259e-07 - accuracy: 1.0000 - val_loss: 2.0032 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.54284\n",
      "Epoch 90/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 8.1582e-07 - accuracy: 1.0000 - val_loss: 1.9238 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.54284\n",
      "Epoch 91/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 7.5192e-07 - accuracy: 1.0000 - val_loss: 1.9248 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.54284\n",
      "Epoch 92/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 7.7407e-07 - accuracy: 1.0000 - val_loss: 1.9803 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.54284\n",
      "Epoch 93/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 6.1565e-07 - accuracy: 1.0000 - val_loss: 1.9076 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.54284\n",
      "Epoch 94/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 7.3792e-07 - accuracy: 1.0000 - val_loss: 1.9580 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.54284\n",
      "Epoch 95/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 6.9254e-07 - accuracy: 1.0000 - val_loss: 2.0133 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.54284\n",
      "Epoch 96/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 6.0457e-07 - accuracy: 1.0000 - val_loss: 2.0395 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.54284\n",
      "Epoch 97/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 5.2782e-07 - accuracy: 1.0000 - val_loss: 1.9402 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.54284\n",
      "Epoch 98/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 5.8497e-07 - accuracy: 1.0000 - val_loss: 1.9592 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.54284\n",
      "Epoch 99/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 5.8608e-07 - accuracy: 1.0000 - val_loss: 2.0327 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.54284\n",
      "Epoch 100/3000\n",
      "851/851 [==============================] - 4s 5ms/step - loss: 4.8103e-07 - accuracy: 1.0000 - val_loss: 2.0234 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.54284\n",
      "Epoch 101/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 5.0807e-07 - accuracy: 1.0000 - val_loss: 2.0385 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.54284\n",
      "Epoch 102/3000\n",
      "851/851 [==============================] - 4s 4ms/step - loss: 4.4167e-07 - accuracy: 1.0000 - val_loss: 2.0436 - val_accuracy: 0.6526\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.54284\n"
     ]
    }
   ],
   "source": [
    "hist3 = model3.fit(X_train, y_train, epochs=3000, batch_size=10, validation_split=0.1, callbacks=[checkpointer,early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.font_manager as fm\n",
    "#fm.get_fontconfig_fonts()\n",
    "#font_path=\"D:\\\\ai\\\\기말대체\\\\NanumFontSetup_TTF_GOTHIC\\\\NanumGothic.ttf\"\n",
    "#font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "#plt.rc('font', family=font_name, size=12) \n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title('Comparison of error rate and accuracy between training and testing datasets(model3)', fontsize=14)\n",
    "\n",
    "plt.plot(hist3.history['loss'])      # 학습 데이터셋의 loss   -> loss \n",
    "plt.plot(hist3.history['val_loss'])  # 테스트 데이터셋의 loss -> val_loss\n",
    "\n",
    "plt.plot(hist3.history['accuracy'])      # 학습 데이터셋의 accuracy    -> accuracy \n",
    "plt.plot(hist3.history['val_accuracy'])  # 테스트 데이터셋의 accuracy  -> val_accuracy \n",
    "\n",
    "plt.legend(['loss','val_loss','accuracy', 'val_accuracy' ])     # 범례\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('model3.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
